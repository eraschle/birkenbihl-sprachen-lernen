# ============================================================================
# Birkenbihl Multi-Provider Configuration
# ============================================================================
#
# This file configures AI providers for the Birkenbihl language learning app.
# Copy this file to settings.yaml and add your API keys directly here.
#
# IMPORTANT: Add settings.yaml to .gitignore to keep API keys private!
#
# ============================================================================

# Provider Configurations
# Each provider needs:
#   - name: Display name (used in UI and CLI)
#   - provider_type: See supported providers below
#   - model: Model identifier (without provider prefix)
#   - api_key: Your actual API key (keep this file private!)
#   - is_default: Set one provider as default (true/false)
#
# Supported provider_type values:
#   OpenAI-based: openai, azure, deepseek, cerebras, fireworks, github, grok,
#                 heroku, ollama, openrouter, together, vercel, litellm
#   Other: anthropic, gemini, groq, cohere, mistral, bedrock

providers:
  # Example: OpenAI GPT-4
  - name: OpenAI GPT-4
    provider_type: openai
    model: gpt-4o
    api_key: sk-your-openai-api-key-here
    is_default: true

  # Example: Anthropic Claude
  # - name: Claude Sonnet
  #   provider_type: anthropic
  #   model: claude-3-5-sonnet-20241022
  #   api_key: sk-ant-your-anthropic-api-key-here
  #   is_default: false

  # Example: Google Gemini
  # - name: Gemini Flash
  #   provider_type: gemini
  #   model: gemini-2.0-flash
  #   api_key: your-google-api-key-here
  #   is_default: false

  # Example: Groq (Fast inference)
  # - name: Groq Llama
  #   provider_type: groq
  #   model: llama-3.3-70b-versatile
  #   api_key: gsk-your-groq-api-key-here
  #   is_default: false

  # Example: DeepSeek (Cost-effective)
  # - name: DeepSeek Chat
  #   provider_type: deepseek
  #   model: deepseek-chat
  #   api_key: sk-your-deepseek-api-key-here
  #   is_default: false

  # Example: Ollama (Local, no API key needed)
  # - name: Ollama Llama
  #   provider_type: ollama
  #   model: llama3.1
  #   api_key: ollama  # Dummy value, not used for local Ollama
  #   is_default: false

  # Example: OpenAI GPT-4o Mini (cheaper/faster)
  # - name: OpenAI GPT-4o Mini
  #   provider_type: openai
  #   model: gpt-4o-mini
  #   api_key: sk-your-openai-api-key-here
  #   is_default: false

# General Settings
target_language: de

# ============================================================================
# Setup Instructions
# ============================================================================
#
# 1. Copy this file to settings.yaml:
#    cp settings.yaml.example settings.yaml
#
# 2. Replace placeholder API keys with your actual keys:
#    - OpenAI: https://platform.openai.com/api-keys
#    - Anthropic: https://console.anthropic.com/settings/keys
#    - Google Gemini: https://aistudio.google.com/app/apikey
#    - Groq: https://console.groq.com/keys
#    - DeepSeek: https://platform.deepseek.com/api_keys
#    - Cohere: https://dashboard.cohere.com/api-keys
#    - Ollama: Local installation, no API key needed (https://ollama.com)
#
# 3. Ensure settings.yaml is in .gitignore (already configured)
#
# 4. Uncomment and configure additional providers as needed
#
# 5. Set one provider as is_default: true
#
# Alternative: Environment Variables (.env file)
# If you prefer, you can keep API keys in .env and reference them here:
#   api_key: ${OPENAI_API_KEY}
# But this requires the keys to be set as environment variables.
#
# ============================================================================
